{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "408a59f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torchvision.datasets import FashionMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6cb2424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "train_set = FashionMNIST(root=\"./data\", train=True, download=True)\n",
    "test_set = FashionMNIST(root=\"./data\", train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "51019a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data to NumPy arrays\n",
    "X_train = np.array(train_set.data).reshape(-1, 784) / 255.0\n",
    "X_test = np.array(test_set.data).reshape(-1, 784) / 255.0\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_train = np.eye(10)[np.array(train_set.targets)]\n",
    "y_test = np.eye(10)[np.array(test_set.targets)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346eac40",
   "metadata": {},
   "source": [
    "# 2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "352ce539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax function\n",
    "def softmax(X):\n",
    "    exps = np.exp(X - np.max(X, axis=1, keepdims=True))\n",
    "    return exps / np.sum(exps, axis=1, keepdims=True)\n",
    "\n",
    "# Gradient descent\n",
    "def gradient_descent(loss_func, X, y, learning_rate=0.5, epochs=100):\n",
    "    n, d = X.shape\n",
    "    k = y.shape[1]\n",
    "    W = np.random.randn(d, k) / np.sqrt(d)\n",
    "    for epoch in range(epochs):\n",
    "        scores = np.dot(X, W)\n",
    "        softmax_output = softmax(scores)\n",
    "        grad = -np.dot(X.T, (y - softmax_output)) / n\n",
    "        W -= learning_rate * grad\n",
    "        loss = loss_func(W, X, y)\n",
    "        if (epoch+1)%10==0:\n",
    "            print(f\"Epoch {epoch + 1}, Loss: {loss}\")\n",
    "    return W\n",
    "\n",
    "# Calculate the loss for L(W)\n",
    "def calculate_L_loss(W, X, y):\n",
    "    scores = np.dot(X, W)\n",
    "    softmax_output = softmax(scores)\n",
    "    loss = -np.sum(y * np.log(softmax_output))\n",
    "    return loss\n",
    "\n",
    "def predict(W, X):\n",
    "    scores = np.dot(X, W)\n",
    "    return np.argmax(scores, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a83c2f",
   "metadata": {},
   "source": [
    "# Running Gradient Decent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "89a0f0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 135.32837449812567\n",
      "Epoch 20, Loss: 120.43910989043378\n",
      "Epoch 30, Loss: 49.83535927525998\n",
      "Epoch 40, Loss: 80.22838849472518\n",
      "Epoch 50, Loss: 55.47235498585658\n",
      "Epoch 60, Loss: 80.1572175880842\n",
      "Epoch 70, Loss: 80.20783650954867\n",
      "Epoch 80, Loss: 59.17931904961713\n",
      "Epoch 90, Loss: 70.30831778137976\n",
      "Epoch 100, Loss: 64.81101974623745\n"
     ]
    }
   ],
   "source": [
    "# Run gradient descent for J(W)\n",
    "W_J = gradient_descent(calculate_J_loss, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0bba2338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 380083.93463238265\n",
      "Epoch 20, Loss: 96651.604971244\n",
      "Epoch 30, Loss: 149879.92377353387\n",
      "Epoch 40, Loss: 92413.8823929142\n",
      "Epoch 50, Loss: 78148.35590485296\n",
      "Epoch 60, Loss: 116359.84786588624\n",
      "Epoch 70, Loss: 46970.920905421124\n",
      "Epoch 80, Loss: 84640.215685404\n",
      "Epoch 90, Loss: 91843.66003399061\n",
      "Epoch 100, Loss: 112521.54924157326\n"
     ]
    }
   ],
   "source": [
    "# Run gradient descent for L(W)\n",
    "W_L = gradient_descent(calculate_L_loss, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853d4b67",
   "metadata": {},
   "source": [
    "# Accuracy for J(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "21f1db0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy for J(W)\n",
    "y_train_pred_J = predict(W_J, X_train)\n",
    "y_test_pred_J = predict(W_J, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7e720a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for J(W) - Training set: 74.7267%\n",
      "Accuracy for J(W) - Test set: 73.6300%\n"
     ]
    }
   ],
   "source": [
    "accuracy_train_J = np.mean(y_train_pred_J == np.argmax(y_train, axis=1))\n",
    "accuracy_test_J = np.mean(y_test_pred_J == np.argmax(y_test, axis=1))\n",
    "\n",
    "print(f\"Accuracy for J(W) - Training set: {accuracy_train_J * 100:.4f}%\")\n",
    "print(f\"Accuracy for J(W) - Test set: {accuracy_test_J * 100:.4f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797afa14",
   "metadata": {},
   "source": [
    "# Accuracy for L(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "17050c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy for L(W)\n",
    "y_train_pred_L = predict(W_L, X_train)\n",
    "y_test_pred_L = predict(W_L, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3590297d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for L(W) - Training set: 76.4183%\n",
      "Accuracy for L(W) - Test set: 75.5800%\n"
     ]
    }
   ],
   "source": [
    "accuracy_train_L = np.mean(y_train_pred_L == np.argmax(y_train, axis=1))\n",
    "accuracy_test_L = np.mean(y_test_pred_L == np.argmax(y_test, axis=1))\n",
    "\n",
    "print(f\"Accuracy for L(W) - Training set: {accuracy_train_L * 100:.4f}%\")\n",
    "print(f\"Accuracy for L(W) - Test set: {accuracy_test_L * 100:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3d50ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
